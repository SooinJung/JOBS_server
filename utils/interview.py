import os
import pandas as pd
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.llms import OpenAI
from routers import pdf_files
from config import FILE_DIR
from utils.common import load_pdf_to_text, summarize_text, load_mock_interview_data
from config import API_KEY

class InterviewSession:
    def __init__(self, token: str, question_num=5, mock_data_path=None):    # í´ë˜ìŠ¤ ì´ˆê¸°í™” ë° í…œí”Œë¦¿, LLM ì²´ì¸ ì„¤ì •
        self.token = token
        self.question_num = question_num
        self.question_index = 0
        self.questions = []
        self.answers = []
        self.resume = self._load_pdf_to_resume()
        self.mock_data_path = mock_data_path
        self.example_questions = self._load_mock_interview_data(mock_data_path)

        self.prompt = PromptTemplate(
            template=self._get_question_template(), 
            input_variables=['resume']
            )
        self.llm = OpenAI(api_key=API_KEY)
        self.llm_chain = LLMChain(prompt=self.prompt, llm=self.llm)
    
    
    async def generate_follow_up_question(self, answer):    # ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜
        follow_up_prompt = PromptTemplate(
            template=self._get_follow_up_template(),
            input_variables=['answer']
            )
        follow_up_chain = LLMChain(prompt=follow_up_prompt, llm=self.llm)
        return follow_up_chain.arun({'answer': answer})
    
    
    async def generate_hint(self, question):    # íŒíŠ¸ ì œê³µ í•¨ìˆ˜
        hint_prompt = PromptTemplate(
            template=self._get_hint_template(), 
            input_variables=['question']
            )
        hint_chain = LLMChain(prompt=hint_prompt, llm=self.llm)
        return hint_chain.arun({'question': question})


    async def generate_feedback(self, answer: str):   # í”¼ë“œë°± ìƒì„± í•¨ìˆ˜
        feedback_prompt = PromptTemplate(
            template=self._get_feedback_template(), 
            input_variables=['answer']
            )
        feedback_chain = LLMChain(prompt=feedback_prompt, llm=self.llm)
        result = await feedback_chain.arun({'answer': answer})
        return result.strip() if result else "í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


    def _load_pdf_to_resume(self):
        if self.token not in pdf_files:
            raise ValueError("í•´ë‹¹ í† í°ì— ëŒ€í•œ PDF íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        pdf_path = os.path.join(FILE_DIR, f"{self.token}.pdf")
        if not os.path.exists(pdf_path):
            raise FileNotFoundError("PDF íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        pdf_text = load_pdf_to_text(pdf_path)
        summarized_text = summarize_text(pdf_text, max_length=1500)
        return summarized_text


    def _load_mock_interview_data(self, csv_path):
        mock_interview_examples = load_mock_interview_data(csv_path)
        examples_text = "\n".join([f"{i+1}. {example}" for i, example in enumerate(mock_interview_examples)])
        return examples_text


    async def add_answer(self, answer):     # ì´ê²Œ ë­˜ê¹Œ??
        self.answers.append(answer)
        recent_qa = "\n".join(  # ìµœê·¼ 5ê°œ ì§ˆë¬¸ - ë‹µë³€ë§Œ ìœ ì§€
        [f"ì§ˆë¬¸ {i+1}: {q}\në‹µë³€ {i+1}: {a}" 
        for i, (q, a) in enumerate(zip(self.questions[-5:], self.answers[-5:]))]
        )
        self.resume = f"{self._load_pdf_to_resume()}\n{recent_qa}"


    async def _generate_question(self):
        try:
            result = await self.llm_chain.arun({'resume': self.resume})
            return result.strip() if result else "ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        except Exception as e:
            return f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        

    async def generate_next_question(self, with_hint=False, with_feedback=False, answer=None):
        question_response = await self._generate_question()
        response = {
            "index": self.question_index + 1,
            "question": question_response if isinstance(question_response, str) else question_response.get('question', 'ì§ˆë¬¸ ì—†ìŒ')
        }

        if with_hint:
            response["hint"] = await self.generate_hint(response["question"])
        if answer:
            response["feedback"] = await self.generate_feedback(answer)
            response["follow_up"] = await self.generate_follow_up_question(answer)
    
        self.questions.append(response["question"])
        self.question_index += 1
        return response

    
    def _get_question_template(self):   # ëŒ€í‘œì§ˆë¬¸ ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        return f'''
        You are an expert AI interviewer.
        Use the following resume to make a question in Korean:
        {{resume}}
        
        Here are example questions from a mock interview dataset:
        {self.example_questions}
        
        The question must:
        1. Be in Korean.
        2. Be specific and tailored to the details of the resume.
        3. Focus on the skills, experiences, or projects mentioned.
        4. Avoid repetition of previously generated questions.
        5. Be similar in style and detail to the examples provided.
        6. Only provide one question at a time.
        7. Be realistic and appropriate for a job interview setting.
        8. Always follow this format: "ì§ˆë¬¸: ~."
        '''
        
    def _get_follow_up_template(self):  # ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        return f'''
        You are an expert AI job interviewer.
        Use the following answer from a candidate to create a follow-up question in Korean:
        {{answer}}
        The follow-up question must:
        1. Be in Korean.
        2. Avoid repetition of previously generated questions.
        3. Focus on details mentioned in the answer.
        4. Explore the reasoning, challenges, results, or methodology in the answer.
        5. Only provide one follow-up question at a time.
        6. Always follow this format: "ì§ˆë¬¸: ~."
        '''
    
    def _get_hint_template(self):       # íŒíŠ¸ ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        return f'''
        You are an expert AI interviewer providing hints.
        Provide a brief hint in Korean to help answer this question effectively:
        ì§ˆë¬¸: {{question}}

        The hint should:
        1. Be concise (1-2 sentences).
        2. Focus on what aspects of experience or skills to highlight.
        3. Be supportive and encouraging.
        4. Use this format: "íŒíŠ¸: ~"
        5. Always include encouraging comments and actionable advice with a kind and supportive tone.
        '''
    
    def _get_feedback_template(self):   # í”¼ë“œë°± ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        return f'''
        You are an expert AI job interview coach. Use the following answer from a candidate to provide detailed feedback in Korean:
        {{answer}}

        The feedback must:
        1. Compliment specific strengths in the answer.
        2. Identify areas where the answer could be more specific or detailed.
        3. Provide concrete examples or suggestions for improvement directly related to the details mentioned in the answer.
        4. Be realistic and appropriate for a professional job interview setting.
        5. Be written in Korean, formatted with clear and professional language.
        6. Always include encouraging comments and actionable advice with a kind and supportive tone.
        Example Feedback:
        "ìš°ì„ , íŒ€ì›ë“¤ì˜ ì¥ì ê³¼ ê´€ì‹¬ì‚¬ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•´ ë³¸ì¸ì´ í•œ ë…¸ë ¥ì˜ ë‹¨ê³„ì™€ ê³¼ì •ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì‹  ë¶€ë¶„ì€ í›Œë¥­í•©ë‹ˆë‹¤! ë‹¤ë§Œ êµ¬ì²´ì ì¸ ê²½í—˜, ì˜ˆë¥¼ ë“¤ì–´ â€˜ì• ë‹ˆë¥¼ ì¢‹ì•„í•˜ëŠ” ì¹œêµ¬ì™€ì˜ ë¼í¬ë¥¼ í˜•ì„±í•˜ê¸° ìœ„í•´ ìš”ì¦˜ ìœ í–‰í•˜ëŠ” ë„·í”Œë¦­ìŠ¤ ì• ë‹ˆë©”ì´ì…˜ ì´ë¦„ì„ ì–¸ê¸‰í•˜ë©° ê°€ê¹Œì›Œì§ˆ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤â€™ì™€ ê°™ì€ êµ¬ì²´ì ì¸ ì˜ˆì‹œê°€ ë¶€ì¡±í•´ ë³´ì…ë‹ˆë‹¤. ë‹¤ìŒì—ëŠ” ì´ëŸ° ë¶€ë¶„ì„ ì–¸ê¸‰í•˜ë©´ì„œ ë‹µë³€í•˜ë©´ ë”ìš±ë” ì‹ ë¢°ê°ì„ ì¤„ ìˆ˜ ìˆì–´ ì¢‹ì„ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤! ğŸ‘"
        When giving examples or suggestions, tailor them to the candidate's answer to make them relevant and specific. Avoid reusing generic or unrelated examples.
        Provide the feedback only, without additional explanations or comments.
        '''
    

